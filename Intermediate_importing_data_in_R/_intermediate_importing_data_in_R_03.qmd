# Importing data from the web (Part 1)

More and more of the information that data scientists are using resides on the 
web. Importing this data into R requires an understanding of the protocols used 
on the web. In this chapter, you'll get a crash course in HTTP and learn to 
perform your own HTTP requests from inside R.

## Import flat files from the web

The utils functions to import flat file data, such as `read.csv()` and 
`read.delim()`, are capable of automatically importing from URLs that point to 
flat files on the web.

You must be wondering whether Hadley Wickham's alternative package, readr, is 
equally potent. Well, figure it out in this exercise! The URLs for both a `.csv` 
file as well as a `.delim` file are already coded for you. It's up to you to 
actually import the data. If it works, that isâ€¦

### Instructions `100 XP` {.unnumbered}

- Load the `readr` package. It's already installed on DataCamp's servers.
- Use `url_csv` to read in the `.csv` file it is pointing to. Use the 
`read_csv()` function. The `.csv` contains column names in the first row. Save 
the resulting data frame as `pools`.
- Similarly, use `url_delim` to read in the online `.txt` file. Use the 
`read_tsv()` function and store the result as potatoes.
- Print `pools` and `potatoes`. Looks correct?

```{.r filename="ex_011.R"}
library("readr")

# Import the csv file: pools
url_csv <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/swimming_pools.csv"

pools <- read_csv(url_csv)

# Import the txt file: potatoes
url_delim <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/potatoes.txt"
potatoes <- read_tsv(url_delim)

# Print pools and potatoes
pools
potatoes
```

## Secure importing

In the previous exercises, you have been working with URLs that all start with 
`http://`. There is, however, a safer alternative to HTTP, namely HTTPS, which 
stands for HyperText Transfer Protocol Secure. Just remember this: HTTPS is 
relatively safe, HTTP is not.

Luckily for us, you can use the standard importing functions with `https://`
connections since R version 3.2.2.

### Instructions `100 XP` {.unnumbered}

- Take a look at the URL in `url_csv`. It uses a secure connection, `https://`.
- Use `read.csv()` to import the file at `url_csv`. The `.csv` file it is 
referring to contains column names in the first row. Call it `pools1`.
- Load the `readr` package. 
- Use `read_csv()` to read in the same `.csv` file in `url_csv`. 
Call it `pools2.`
- Print out the structure of `pools1` and `pools2`. Looks like the importing 
went equally well as with a normal `http` connection!


```{.r filename="ex_012.R"}
# https URL to the swimming_pools csv file.
url_csv <-
"https://s3.amazonaws.com/assets.datacamp.com/production/course_1478/
datasets/swimming_pools.csv
"

# Import the file using read.csv(): pools1
pools1 <- read.csv(url_csv)

# Load the readr package
library(readr)

# Import the file using read_csv(): pools2
pools2 <- read_csv(url_csv)

# Print the structure of pools1 and pools2
str(pools1)
str(pools2)
```

## Importing Excel files from the web

When you learned about `gdata`, it was already mentioned that `gdata` can 
handle `.xls` files that are on the internet. `readxl` can't, at least not yet. 
The URL with which you'll be working is already available in the sample code. 
You will import it once using `gdata` and once with the `readxl` package via a 
workaround.

### Instructions `100 XP` {.unnumbered}

- Load the `readxl` and `gdata` packages.
- Import the .xls file located at the URL url_xls using read.xls() from gdata.  
- Store the resulting data frame as excel_gdata.
- You can not use read_excel() directly with a URL. Complete the following 
instructions to work around this problem:
- Use download.file() to download the .xls file behind the URL and store it 
locally as "local_latitude.xls".
- Call read_excel() to import the local file, "local_latitude.xls". Name the 
resulting data frame excel_readxl.

```{.r filename="ex_013.R"}
# Load the readxl and gdata package
library(readxl)
library(gdata)


# Specification of url: url_xls
url_xls <- 
"http://s3.amazonaws.com/assets.datacamp.com/production/
course_1478/datasets/latitude.xls"

# Import the .xls file with gdata: excel_gdata
excel_gdata <- read.xls(url_xls)

# Download file behind URL, name it local_latitude.xls
dest_path <- file.path("~", "local_latitude.xls")
download.file(url_xls, "local_latitude.xls")

# Import the local .xls file with readxl: excel_readxl
excel_readxl <- read_excel("local_latitude.xls")
```

## Donwloading any file, secure or not

In the previous exercise you've seen how you can read excel files on the web 
using the read_excel package by first downloading the file with the 
`download.file()` function.

There's more: with `download.file()` you can download any kind of file from the 
web, using `HTTP` and `HTTPS:` images, executable files, but also `.RData` 
files. An `RData` file is very efficient format to store R data.

You can load data from an RData file using the `load()` function, but this 
function does not accept a URL string as an argument. In this exercise, you'll 
first download the RData file securely, and then import the local data file.

### Instructions `100 XP` {.unnumbered}

- Take a look at the URL in `url_rdata`. It uses a secure connection, 
`https://`. This URL points to an `RData` file containing a data frame with some 
metrics on different kinds of wine.
- Download the file at`url_rdata` using `download.file()`. Call the file 
`"wine_local.RData"` in your working directory.
- Load the file you created, `wine_local.RData`, using the `load()` function. 
It takes one argument, the path to the file, which is just the filename in our 
case. 
After running this command, the variable wine will automatically be available 
in your workspace. 
- Print out the `summary()` of the wine dataset.

```{.r filename="ex_014.R"}
# https URL to the wine RData file.
url_rdata <- 
"https://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/wine.RData"

# Download the wine file to your working directory
download.file(url_rdata, "wine_local.RData")

# Load the wine data into your workspace using load()
load("wine_local.RData")

# Print out the summary of the wine data
summary(wine)
```
## HTTP? httr! (1)
Downloading a file from the Internet means sending a `GET` request and 
receiving the file you asked for. Internally, all the previously discussed 
functions use a GET request to download files.

`httr` provides a convenient function, `GET()` to execute this `GET` request. 
The result is a response object, that provides easy access to the status code, 
content-type and, of course, the actual content.

You can extract the content from the request using the `content()` function. 
At the time of writing, there are three ways to retrieve this content: as a raw 
object, as a character vector, or an R object, such as a list. If you don't tell 
`content()` how to retrieve the content through the as argument, it'll try its 
best to figure out which type is most appropriate based on the content-type.

### Instructions `100 XP` {.unnumbered}
- Load the httr package. It's already installed on DataCamp's servers.
- Use GET() to get the URL stored in url. Store the result of this GET() call 
as resp.
- Print the resp object. What information does it contain?
- Get the content of resp using content() and set the as argument to "raw". 
Assign the resulting vector to raw_content.
- Print the first values in raw_content with head().


```{.r filename="ex_015.R"}
# Load the httr package
library(httr)

# Get the url, save response to resp
url <- "http://www.example.com/"

resp <- GET(url)
# Print resp
print(resp)

# Get the raw content of resp: raw_content
raw_content <- content(resp, as = 'raw')

# Print the head of raw_content
head(raw_content)

```


## HTTP? httr! (2)

Web content does not limit itself to HTML pages and files stored on remote 
servers such as DataCamp's Amazon S3 instances. There are many other data 
formats out there. A very common one is JSON. This format is very often used by
so-called Web APIs, interfaces to web servers with which you as a client can
communicate to get or store information in more complicated ways.

You'll learn about Web APIs and JSON in the video and exercises that follow, 
but some experimentation never hurts, does it?

### Instructions `100 XP` {.unnumbered}

- Use `GET()` to get the url that has already been specified in the sample code. 
Store the response as resp.
- Print `resp.` What is the content-type?
- Use `content()` to get the content of `resp.` Set the as argument to 
`"text"`. Simply print out the result. What do you see?
- Use `content()` to get the content of resp, but this time do not specify a 
second argument. R figures out automatically that you're dealing with a JSON, 
and converts the JSON to a named R list.

```{.r filename="ex_016.R"}
# httr is already loaded
# Get the url
url <- "http://www.omdbapi.com/?
apikey=72bc447a&t=Annie+Hall&y=&plot=short&r=json"
resp <- GET(url)
# Print resp
print(resp)
# Print content of resp as text
print(content(resp, as = "text"))
# Print content of resp
print(content(resp))
```
